# -*- coding: utf-8 -*-
"""Entire Pipeline.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ERO-_0EMyJW621dFhzAe-ijHGNfeisei

# Imports
"""

!pip install opencv-python-headless
!pip install pyzbar
!apt-get install libzbar0

!pip install paddleocr
!python -m pip install paddlepaddle-gpu==2.5.0.post118 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html

import cv2
import os
import numpy as np
from datetime import datetime
from google.colab.patches import cv2_imshow  # Required to show images in Colab
from pyzbar.pyzbar import decode
import paddleocr
from paddleocr import PaddleOCR
from PIL import Image
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

ocr = PaddleOCR(lang="en", rec_model_type='en', use_gpu=False, rec_algorithm = 'CRNN', rec_image_inverse = False, det_db_thresh=0.4, show_log = False)

from google.colab import drive
drive.mount('/content/drive')

!unzip "/content/drive/MyDrive/OCR-SKU/Box Counting Details.zip"

"""# Utils"""

def make_statement(nums):
    unit = 'g'
    for i in range(len(nums)):
        s = str(nums[i])
        if len(s)>3 and '.' not in s:
            nums[i] = int(s[:3])
        if '.' in s:
            ind = s.index('.')
            nums[i] = float(s[:ind+2])
    if nums[-1]<=4:
        unit = 'kg'

    if len(nums)==1:
        return f'{nums[0]} Pieces'
    if len(nums)==2:
        return f'{nums[0]} Pieces X {nums[1]}{unit}'
    if len(nums)==3:
        if nums[0]==(nums[1]*nums[2])/1000:
            return f'{nums[0]} kg ({nums[1]} Pieces X {nums[2]}{unit})'
        else:
            return f'{nums[0]} Pieces X {nums[1]} Pieces X {nums[2]}{unit}'
    return nums

def get_nums(statement):
    nums = []
    curr = ''
    for i in range(len(statement)):
        if statement[i].isdigit() or (len(curr)>0 and statement[i]=='.'):
            curr+=statement[i]
            if i<len(statement)-1 and statement[i+1]=='.': continue

            if i==len(statement)-1 or not statement[i+1].isdigit():
                if float(curr)==int(float(curr)): nums.append(int(curr))
                else: nums.append(float(curr))
                curr=''
    return nums


def get_target_statement(words):
    req = ''
    for sentence in words:
        if 'X' in sentence or 'x' in sentence or 'Ã—' in sentence:
            nums = get_nums(sentence)
            if len(nums)>=2:
                req = sentence
    if len(req)>2:
        return(req)
    return None

def load_image_with_orientation(image_path):
    img = Image.open(image_path)

    # Check if the image has Exif data with orientation information
    if hasattr(img, '_getexif'):
        exif = img._getexif()
        if exif is not None:
            orientation = exif.get(0x0112)
            # Orientation values: 1, 3, 6, 8 (See Exif documentation for details)
            if orientation == 3:
                img = img.rotate(180, expand=True)
            elif orientation == 6:
                img = img.rotate(270, expand=True)
            elif orientation == 8:
                img = img.rotate(90, expand=True)

    return img

def get_code(image_path):
    image = cv2.imread(image_path)
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    qr_codes = decode(gray_image)

    if len(qr_codes) > 0:
        for qr_code in qr_codes:
            # Extract the QR code data and convert it to a string
            qr_data = qr_code.data.decode("utf-8")
            return qr_data
    return None

def extract_central_part(image_path, border_size=100):
    # Read the image using cv2.imread()
    img = cv2.imread(image_path)

    # Check if the image was successfully read
    if img is None:
        print("Error: Unable to read the image.")
        return None

    # Get the dimensions of the image
    img_height, img_width, _ = img.shape

    # Calculate the boundaries for the central part extraction
    start_x = border_size
    end_x = img_width - border_size
    start_y = border_size
    end_y = img_height - border_size

    # Extract the central part of the image
    central_part = img[start_y:end_y, start_x:end_x]

    return central_part

np.random.seed(42)

def quantify_font_color(image_path):
    # Load the image
    image = extract_central_part(image_path)
    #cv2_imshow(image)

    # Convert the image to the HSV color space
    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

    # Define the range of colors to threshold
    lower_red = np.array([0, 50, 50])
    upper_red = np.array([10, 255, 255])
    lower_blue = np.array([110, 50, 50])
    upper_blue = np.array([130, 255, 255])
    lower_green = np.array([50, 50, 50])
    upper_green = np.array([70, 255, 255])

    # Threshold the image to extract the font colors
    mask_red = cv2.inRange(hsv_image, lower_red, upper_red)
    mask_blue = cv2.inRange(hsv_image, lower_blue, upper_blue)
    mask_green = cv2.inRange(hsv_image, lower_green, upper_green)

    # Calculate the percentage of each color in the image
    total_pixels = image.shape[0] * image.shape[1]
    red_pixels = np.count_nonzero(mask_red) / total_pixels
    blue_pixels = np.count_nonzero(mask_blue) / total_pixels
    green_pixels = np.count_nonzero(mask_green) / total_pixels

    # Quantify the font color on a scale of 1-100
    #font_color = (red_pixels * 100 + blue_pixels * 100 + green_pixels * 100) / 3
    return (red_pixels * 100, blue_pixels * 100, green_pixels * 100)

def classify_test_element(data_array, test_element, threshold = 0.005):
    # Get unique classes
    unique_classes = np.unique(data_array[:, -1])

    labels = []
    for class_label in unique_classes:
        # Filter rows for the current class
        class_data = data_array[data_array[:, -1] == class_label]

        # Find the range for each column
        min_num1 = np.min(class_data[:, 0])
        max_num1 = np.max(class_data[:, 0])

        min_num2 = np.min(class_data[:, 1])
        max_num2 = np.max(class_data[:, 1])

        min_num3 = np.min(class_data[:, 2])
        max_num3 = np.max(class_data[:, 2])

        # Check if the test_element falls within the unique range for this class
        if min_num1 - threshold <= test_element[0] <= max_num1 + threshold and \
           min_num2 - threshold <= test_element[1] <= max_num2 + threshold and \
           min_num3 - threshold <= test_element[2] <= max_num3 + threshold:
            labels.append(class_label)
    if len(labels)==1: return labels[0]

    # If no unique match found, return 0
    return 0

arr = np.array(pd.read_csv('RGB_ranges.csv', names = [1,2,3,4]))

names = ['Amul Pasteurized butter salted', 'Amul Pasteurized butter unsalted', 'Amul Pasteurized table butter', 'Amul White butter Unsalted', 'Amul Pasteurized butter',
         'Amul White butter', 'Amul Butter Tinned', 'Amul pasteurized water buffalo and cow milk butter salted',
         'Amul pasteurized water buffalo and cow milk butter unsalted', 'Infant milk food infant milk substitute']

names = [i.upper() for i in names]
for name in names:
    if 'PASTEURIZED' in name:
        new_name = name.replace('PASTEURIZED', 'PASTEURISED')
        names.append(new_name)

names.append('AMUL BUTTER')

d = {1: 'NAME: AMUL PASTEURIZED BUTTER SALTED, NET WEIGHT: 20 X 500g',
     10: 'NAME: AMUL PASTEURIZED TABLE BUTTER, NET WEIGHT: 8 X 8 X 200g',
     11: 'NAME: AMUL WHITE BUTTER UNSALTED, NET WEIGHT: 150 X 100g',
     12: 'NAME: AMUL PASTEURIZED BUTTER, NET WEIGHT: 30 X 500g',
     13: 'NAME: AMUL WHITE BUTTER, NET WEIGHT: 15kg',
     14: 'NAME: AMUL PASTEURIZED BUTTER, NET WEIGHT: 150 X 100g',
     15: 'NAME: AMUL WHITE BUTTER, NET WEIGHT: 30 X 500g',
     16: 'NAME: AMUL PASTEURIZED TABLE BUTTER, NET WEIGHT: 15kg',
     17: 'NAME: AMUL PASTEURIZED BUTTER, NET WEIGHT: 60 X 100g',
     18: 'NAME: AMUL PASTEURIZED TABLE BUTTER, NET WEIGHT: 10 X 1kg',
     19: 'NAME: AMUL PASTEURIZED BUTTER, NET WEIGHT: 10 X 1kg',
     2: 'NAME: AMUL PASTEURIZED BUTTER SALTED, NET WEIGHT: 100 X 100g',
     20: 'NAME: AMUL BUTTER TINNED, NET WEIGHT: 36 X 400g',
     21: 'NAME: AMUL PASTEURIZED BUTTER SALTED, NET WEIGHT: 10 X 100 X 8G',
     22: 'NAME: AMUL PASTEURIZED BUTTER, NET WEIGHT: 36 X 400g',
     3: 'NAME: AMUL PASTEURIZED BUTTER UNSALTED, NET WEIGHT: 20 X 500g',
     4: 'NAME: AMUL PASTEURIZED BUTTER UNSALTED, NET WEIGHT: 100 X 100g',
     5: 'NAME: AMUL PASTEURIZED WB CM BUTTER SALTED, NET WEIGHT: 100 X 100g',
     6: 'NAME: AMUL PASTEURIZED WB CM BUTTER UNSALTED, NET WEIGHT: 20 X 500g',
     7: 'NAME: AMUL PASTEURIZED WB CM BUTTER UNSALTED, NET WEIGHT: 20 X 500g',
     8: 'NAME: AMUL PASTEURIZED BUTTER, NET WEIGHT: 16 X 1kg',
     9: 'NAME: AMUL PASTEURIZED TABLE BUTTER, NET WEIGHT: 40 X 500g',
     60: 'NAME: AMULSPRAY INFANT MILK FOOD INFANT MILK SUBSTITUTE, NET WEIGHT: 2 X 420 X 13.5g'}

"""# Code"""

my_path = '/content/Box Counting Details/Amul Butter/'
files = sorted(os.listdir(my_path))
times = []

for f in files:
    if '.xlsx' in f: continue
    print('\n',f)

    codes = []
    for image in os.listdir(my_path+f):
        if image[-3:]=='jpg' or image[-3:]=='png':
            # Read the image file.
            image_path = f"{my_path}{f}/{image}"
            code = get_code(image_path)
            if code: codes.append(code)
    if codes:
        #codes = np.array(codes)
        print('\tBAR CODE:', codes)
        continue

    vals = []
    for image in os.listdir(my_path+f):
        if image[-3:]=='jpg' or image[-3:]=='png':
            # Read the image file.
            image_path = f"{my_path}{f}/{image}"
            r,g,b = quantify_font_color(image_path)
            result = classify_test_element(arr, [r,g,b])
            if result: vals.append(result)
    if vals:
        print(f'\t{d[int(vals[0])]}')
        continue

    net_weight = ''
    name = ''
    for image in os.listdir(my_path+f):
        if image[-3:]=='jpg' or image[-3:]=='png':
            # Read the image file.
            image_path = f"{my_path}{f}/{image}"
            img = load_image_with_orientation(image_path)
            img = np.array(img.resize((800, 300)))
            img = img[:,100:700]

            #result = ocr.ocr(image_path)
            result = ocr.ocr(img)
            words = []
            for line in result:
                for word_info in line:
                    words.append(word_info[1][0])
            #print(words)
            req = get_target_statement(words)
            if req:
                nums = get_nums(req)
                net_weight = make_statement(nums)

            entire_text = ' '.join(words).upper()
            for i in names:
                if i in entire_text:
                    name = i
                    break
    print('\tName:', name)
    print('\tNet weight:', net_weight)



def get_sku(image_path):
    code = get_code(image_path)
    if code:
        print('BAR CODE:', code)
        return code


    r,g,b = quantify_font_color(image_path)
    result = classify_test_element(arr, [r,g,b])
    if result:
        print(f'{d[int(result)]}')
        return result


    net_weight = ''
    name = ''
    img = load_image_with_orientation(image_path)
    img = np.array(img.resize((800, 300)))
    img = img[:,100:700]

    #result = ocr.ocr(image_path)
    result = ocr.ocr(img)
    words = []
    for line in result:
        for word_info in line:
            words.append(word_info[1][0])
    #print(words)
    req = get_target_statement(words)
    if req:
        nums = get_nums(req)
        net_weight = make_statement(nums)

    entire_text = ' '.join(words).upper()
    for i in names:
        if i in entire_text:
            name = i
            break
    print('Name:', name)
    print('Net weight:', net_weight)

result = get_sku('/content/IMG-20230708-WA0118.jpg')

